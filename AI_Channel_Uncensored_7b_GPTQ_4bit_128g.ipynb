{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td>\n",
        "    <center><font color=\"#CC3E3E\" size=\"6\">‚ö†Ô∏è <u><b>!! <font color=\"#FFD700\" size=\"6\">WAJIB GPU MODE</font> !!</b></u> ‚ö†Ô∏è</font></center>\n",
        "\n",
        "\n",
        " <font color=\"#CC3E3E\">**PERINGATAN**:</font>\n",
        "\n",
        "1. Jangan pernah sering mengganti akun untuk mengatasi limit pengguaan google colab, </br> karena itu sudah termasuk dalam pelanggaran dalam  [kebijakan baru][baru] </br>(usahakan tidak menggunakan lebih dari 3 akun).\n",
        "2. DiKarenakan SYARAT & KETENTUAN Google sewaktu-waktu bisa berubah, ada kemungkinan </br>mempengaruhi Colab ini. Jika terjadi masalah/error harap segerapa Lapor di komentar</br> youtube kami üôè.\n",
        "\n",
        "[baru]:https://research.google.com/colaboratory/intl/id/faq.html\n",
        "\n",
        "</br>\n",
        "    </td>\n",
        "     <td>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     |</br>\n",
        "     </td>\n",
        "    <td>\n",
        "    \n",
        "## **<center>Jangan Lupa Subscribe Youtube Channel Kami üòÖ</center>**\n",
        "\n",
        "<div align=\"center\">\n",
        " <font size=\"12\">üëâ</font> <a href=\"https://www.youtube.com/@AI-C\" target=\"_blank\" rel=\"nofollow\"> <img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgwdXnFFDU62Bb9ZA5GqKcD1bqdz3CDWodJYi6RF4w1IqUI8IsSal_acYDNfrjLTYsXcKLysqKZ6hjYsQdAgpr_WZ2ycgAyzGOqX3iuQq5BuIyKLTidAjGKTt3N2k9GDwO8EEdMjOoWonwEs-XSYbbKDaxv0648evogqJIFd_qsbmK6X62849Kcm5frSvEr/s1234/Subscribe.png\" width=\"310\"/> </a> <font size=\"14\" >üôè</font></div>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n"
      ],
      "metadata": {
        "id": "Km327pg1HYas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCFOzsQSHbjM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title uncensored-7b-GPTQ\n",
        "\n",
        "%cd /content\n",
        "!apt-get -y install -qq aria2\n",
        "\n",
        "!git clone https://github.com/A-I-Channel/text-gen-webui /content/text-generation-webui\n",
        "%cd /content/text-generation-webui\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/WizardLM-7B-uncensored-GPTQ/raw/main/config.json -d /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/WizardLM-7B-uncensored-GPTQ/raw/main/generation_config.json -d /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ -o generation_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/WizardLM-7B-uncensored-GPTQ/raw/main/special_tokens_map.json -d /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ -o special_tokens_map.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/WizardLM-7B-uncensored-GPTQ/resolve/main/tokenizer.model -d /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ -o tokenizer.model\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/WizardLM-7B-uncensored-GPTQ/raw/main/tokenizer_config.json -d /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ -o tokenizer_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/WizardLM-7B-uncensored-GPTQ/resolve/main/WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors -d /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ -o WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors\n",
        "\n",
        "!echo \"dark_theme: true\" > /content/settings.yaml\n",
        "!echo \"chat_style: wpp\" >> /content/settings.yaml\n",
        "!echo \"mode: 'instruct'\" >> /content/settings.yaml\n",
        "!echo \"instruction_template: 'Wizard-Mega WizardLM'\" >> /content/settings.yaml\n",
        "\n",
        "%cd /content/text-generation-webui\n",
        "!python server.py --share --settings /content/settings.yaml --wbits 4 --groupsize 128 --loader AutoGPTQ --model /content/text-generation-webui/models/WizardLM-7B-uncensored-GPTQ"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}